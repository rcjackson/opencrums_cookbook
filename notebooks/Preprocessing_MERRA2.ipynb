{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae4a2fc",
   "metadata": {},
   "source": [
    "# Preprocessing MERRA2 data\n",
    "\n",
    "In order for TensorFlow to be able to properly ingest MERRA2 aerosol data, preprocessing the data to only include specific regions of interest must be done first. The following code snippets will take a sample MERRA2 aerosol data file and crop it to a given lat/lon box that you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8564cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef256af",
   "metadata": {},
   "source": [
    "Here, we specify the input dataset path *in_merra_path*, the output cropped dataset path *out_path*, and the subset of variables that we want. In this case, the variables that are chosen represent the mass and column flux of the different aerosol species in MERRA5. Other variables such as Angstrom exponent and AOD exist but are related to the total column mass. Therefore, one can use such physical reasoning to reduce the dimensionality of the input space to the variables that would most likely be able to describe the physical characteristics of the aerosol/meteorological regime and remove potentially redundant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31772199",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_merra_path = '/lcrc/group/earthscience/rjackson/MERRA2/2010/*.nc4' \n",
    "out_path = '/lcrc/group/earthscience/rjackson/MERRA2/hou_temp/'\n",
    "    \n",
    "# Only include the variables we want. We can choose the relevant features of interest by \n",
    "variable_list = [\"BCCMASS\", \"BCFLUXU\", \"BCFLUXV\",\n",
    "    \"BCSMASS\", \"DMSCMASS\", \"DMSSMASS\", \n",
    "    \"DUCMASS\", \"DUCMASS25\", \"DUFLUXU\", \"DUFLUXV\",\n",
    "    \"DUSMASS\", \"DUSMASS25\", \"OCCMASS\", \"OCFLUXU\",\n",
    "    \"OCFLUXV\", \"OCSMASS\", \"SO2CMASS\", \"SO2SMASS\",\n",
    "    \"SO4CMASS\", \"SO4SMASS\", \"SSCMASS\", \"SSCMASS25\",\n",
    "    \"SSFLUXU\", \"SSFLUXV\", \"SSSMASS\", \"SSSMASS25\",\n",
    "    \"SUFLUXU\", \"SUFLUXV\"]\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383375c",
   "metadata": {},
   "source": [
    "Here, you specify the domain to where you want to crop your input data using the *ax_extent* variable. The *ax_extent* variable is a 4-member list with [*lon_min*, *lon_max*, *lat_min*, *lat_max*] as members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a770a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'HOU'\n",
    "if code == 'HOU':\n",
    "    ax_extent = [-105, -85, 25, 35]\n",
    "elif code == 'SEUS':\n",
    "    ax_extent = [-90, -75, 30, 37.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41222382",
   "metadata": {},
   "source": [
    "Finally, we use *xarray* in order to do the data cropping and save the output to another series of netCDF files. This code will work on either a singular file or a series of netCDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ds = xr.open_mfdataset(in_merra_path)\n",
    "print(inp_ds)\n",
    "for variable in variable_list:\n",
    "    if os.path.exists(out_path + '%s.nc' % (variable)):\n",
    "        continue\n",
    "    print(\"Processing %s\" % variable)\n",
    "    in_ds1 = inp_ds[variable]\n",
    "    lon_inds = np.argwhere(\n",
    "        np.logical_and(\n",
    "            in_ds1.lon.values >= ax_extent[0],\n",
    "            in_ds1.lon.values <= ax_extent[1])).astype(int)\n",
    "    lat_inds = np.argwhere(\n",
    "        np.logical_and(\n",
    "            in_ds1.lat.values >= ax_extent[2],\n",
    "            in_ds1.lat.values <= ax_extent[3])).astype(int)\n",
    "    in_ds1 = in_ds1[:, int(lat_inds[0]):int(lat_inds[-1]), int(lon_inds[0]):int(lon_inds[-1])]\n",
    "    in_ds1.load()\n",
    "    in_ds1.to_netcdf(out_path + '%s.nc' % (variable))\n",
    "    in_ds1.close()\n",
    "inp_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80daf5b7-625a-4a50-9956-8e3e77ed0ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
